#!/usr/bin/env python
import os
import pandas as pd
import numpy as np
import seaborn as sns
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from matplotlib.image import imread
get_ipython().run_line_magic('matplotlib', 'inline')

my_data_dir = 'C:\\Users\\Marcial\\Pierian-Data-Courses\\cell_images'
os.listdir(my_data_dir)
test_path = my_data_dir+'\\test\\'
train_path = my_data_dir+'\\train\\'

os.listdir(test_path)
os.listdir(train_path)
os.listdir(train_path+'\\parasitized')[0]
para_cell = train_path+'\\parasitized'+'\\C100P61ThinF_IMG_20150918_144104_cell_162.png'

para_img= imread(para_cell)
plt.imshow(para_img)
para_img.shape

unifected_cell_path = train_path+'\\uninfected\\'+os.listdir(train_path+'\\uninfected')[0]
unifected_cell = imread(unifected_cell_path)
plt.imshow(unifected_cell)
len(os.listdir(train_path+'\\parasitized'))
len(os.listdir(train_path+'\\uninfected'))
unifected_cell.shape
para_img.shape
# Other options: https://stackoverflow.com/questions/1507084/how-to-check-dimensions-of-all-images-in-a-directory-using-python
dim1 = []
dim2 = []
for image_filename in os.listdir(test_path+'\\uninfected'):
    
    img = imread(test_path+'\\uninfected'+'\\'+image_filename)
    d1,d2,colors = img.shape
    dim1.append(d1)
    dim2.append(d2)

sns.jointplot(dim1,dim2)
np.mean(dim1)
np.mean(dim2)
image_shape = (130,130,3)

# ## Preparing the Data for the model
# There is too much data for us to read all at once in memory. We can use some built in functions in Keras to automatically process the data, generate a flow of batches from a directory, and also manipulate the images.
# ### Image Manipulation
# Its usually a good idea to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. We can use the **ImageDataGenerator** to do this automatically for us. Check out the documentation for a full list of all the parameters you can use here!
from tensorflow.keras.preprocessing.image import ImageDataGenerator
help(ImageDataGenerator)
image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees
                               width_shift_range=0.10, # Shift the pic width by a max of 5%
                               height_shift_range=0.10, # Shift the pic height by a max of 5%
                               rescale=1/255, # Rescale the image by normalzing it.
                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)
                               zoom_range=0.1, # Zoom in by 10% max
                               horizontal_flip=True, # Allo horizontal flipping
                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value
                              )

plt.imshow(para_img)
plt.imshow(image_gen.random_transform(para_img))
plt.imshow(image_gen.random_transform(para_img))

# ### Generating many manipulated images from a directory
# In order to use .flow_from_directory, you must organize the images in sub-directories. This is an absolute requirement, otherwise the method won't work. The directories should only contain images of one class, so one folder per class of images.
# Structure Needed:
# * Image Data Folder
#     * Class 1
#         * 0.jpg
#         * 1.jpg
#         * ...
#     * Class 2
#         * 0.jpg
#         * 1.jpg
#         * ...
#     * ...
#     * Class n
image_gen.flow_from_directory(train_path)
image_gen.flow_from_directory(test_path)


# Creating the Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D

#https://stats.stackexchange.com/questions/148139/rules-for-selecting-convolutional-neural-network-hyperparameters
model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(128))
model.add(Activation('relu'))

model.add(Dropout(0.5))

# Last layer, remember its binary so we use sigmoid
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

early_stop = EarlyStopping(monitor='val_loss',patience=2)
help(image_gen.flow_from_directory)
batch_size = 16

train_image_gen = image_gen.flow_from_directory(train_path,
                                               target_size=image_shape[:2],
                                                color_mode='rgb',
                                               batch_size=batch_size,
                                               class_mode='binary')

test_image_gen = image_gen.flow_from_directory(test_path,
                                               target_size=image_shape[:2],
                                               color_mode='rgb',
                                               batch_size=batch_size,
                                               class_mode='binary',shuffle=False)

train_image_gen.class_indices
import warnings
warnings.filterwarnings('ignore')
results = model.fit_generator(train_image_gen,epochs=20,
                              validation_data=test_image_gen,
                             callbacks=[early_stop])

from tensorflow.keras.models import load_model
model.save('malaria_detector.h5')
losses = pd.DataFrame(model.history.history)
losses[['loss','val_loss']].plot()
model.metrics_names
model.evaluate_generator(test_image_gen)
from tensorflow.keras.preprocessing import image
# https://datascience.stackexchange.com/questions/13894/how-to-get-predictions-with-predict-generator-on-streaming-test-data-in-keras
pred_probabilities = model.predict_generator(test_image_gen)
pred_probabilities
test_image_gen.classes
predictions = pred_probabilities > 0.5
# Numpy can treat this as True/False for us
predictions
from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(test_image_gen.classes,predictions))
confusion_matrix(test_image_gen.classes,predictions)
# # Predicting on an Image
# Your file path will be different!
my_image = image.load_img(para_cell,target_size=image_shape)
type(my_image)
my_image = image.img_to_array(my_image)
type(my_image)
my_image = np.expand_dims(my_image, axis=0)
model.predict(my_image)
train_image_gen.class_indices
test_image_gen.class_indices
